{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews Preparation for Natural Language Processing\n",
    "\n",
    "Add review_scores_rating from listings data to reviews data. Listings data only has review scores pertaining to the most recent review for a particular listing. This means that there will be many reviews that do not have a score, which we will remove during the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in libraries\n",
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increase number of columns and rows displayed by Pandas\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "#Ignore warnings\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to listings and review data\n",
    "path = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python Projects\\In Progress\\Air BnB - SF\\Data\\02_Intermediate/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse in listings dates\n",
    "date = ['calendar_last_scraped', 'calendar_updated', 'first_review' ,'host_since', 'last_review']\n",
    "\n",
    "#Read in Airbnb Listings Data\n",
    "listings = pd.read_csv(path + '01_04_2020_Listings_Cleaned.csv',parse_dates=date, index_col=0, low_memory=True, sep=',')\n",
    "\n",
    "#Read in Airbnb Calendar and Reviews data\n",
    "reviews = pd.read_csv(path + '01_04_2020_Reviews_Cleaned.csv', sep = ',',\n",
    "                       parse_dates=['date'], low_memory=True,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview listings\n",
    "listings.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview reviews data\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge review_scores_rating from listings to corresponding reviews**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings on airbnb\n",
    "At airbnb hosts and guests are not reviewed in same. Where guests simply get a written review hosts also receives a star rating from 1 to 5 on 6 parameters:\n",
    "\n",
    "Accuracy\n",
    "Communication\n",
    "Cleanliness\n",
    "Location\n",
    "Check In\n",
    "Value\n",
    "which are also calculated into one overall rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_cols=['host_is_superhost', 'host_response_time', 'latitude', 'longitude', \n",
    "               'neighbourhood_cleansed', 'number_of_reviews', 'room_type','id']\n",
    "\n",
    "#Merge Review scores from listings to reviews dataframe. Merge on last review to confirm scores are assigned to proper review\n",
    "reviews = reviews.merge(listings[listings_cols], left_on= ['listing_id'], \n",
    "                              right_on=['id'], suffixes=('_review', '_listings'))\n",
    "\n",
    "#Drop duplicate values\n",
    "reviews.drop_duplicates(inplace=True)\n",
    "\n",
    "#Drop unnecessary columns from review_scores\n",
    "reviews.drop(columns=['id_listings'], axis = 1, inplace= True)\n",
    "\n",
    "#View review_scores shape\n",
    "print('Data shape:', reviews.shape)\n",
    "\n",
    "#Check\n",
    "reviews.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick clean up for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View missing values in review_scores\n",
    "print('\\nMissing values:\\n', reviews.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with host_response_time\n",
    "reviews = reviews[-reviews.host_response_time.isna()]\n",
    "\n",
    "#View updated reviews shape\n",
    "print('Updated reviews data shape:',reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data \n",
    "\n",
    "We'll take a 5% sample for our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample\n",
    "sample = reviews.sample(frac=0.05,random_state=1)\n",
    "\n",
    "#Sample Preview\n",
    "print('Sample shape:', sample.shape)\n",
    "display(sample.head().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop Word Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#check stopwords\n",
    "stop =stopwords.words('english')\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude stopwords from comments\n",
    "sample['comments_parsed'] = sample['comments'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#Check\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and instantiate sentiment intensity analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#Write fuctions to capture positive, negative, neutral, and compound scores to later apply to reviews.comments_parsed\n",
    "def neg_scores(comment):\n",
    "    #Function to capture neg semantic score \n",
    "    score = analyzer.polarity_scores(comment)['neg']\n",
    "    return score\n",
    "\n",
    "def pos_scores(comment):\n",
    "    #Function to capture positive semantic score \n",
    "    score = analyzer.polarity_scores(comment)['pos']\n",
    "    return score\n",
    "\n",
    "def neutral_scores(comment):\n",
    "    #Function to capture negative semantic score \n",
    "    score = analyzer.polarity_scores(comment)['neu']\n",
    "    return score\n",
    "\n",
    "def compound_scores(comment):\n",
    "    #Function to capture compound semantic score \n",
    "    score = analyzer.polarity_scores(comment)['compound']\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply functions to reviews and assign scores to unique column\n",
    "sample['sentiment_neg']= sample['comments_parsed'].swifter.apply(neg_scores)\n",
    "sample['sentiment_pos']= sample['comments_parsed'].swifter.apply(pos_scores)\n",
    "sample['sentiment_neu']= sample['comments_parsed'].swifter.apply(neutral_scores)\n",
    "sample['sentiment_compound']= sample['comments_parsed'].swifter.apply(compound_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to write processed data\n",
    "path = r'C:\\Users\\kishe\\Documents\\Data Science\\Projects\\Python Projects\\In Progress\\Air BnB - SF\\Data\\03_Processed'\n",
    "\n",
    "#Write to csv\n",
    "sample.to_csv(path + '/01_10_2020_Reviews_Processed_Text_Analysis.csv',sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
